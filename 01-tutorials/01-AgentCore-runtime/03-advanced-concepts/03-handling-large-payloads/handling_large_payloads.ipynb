{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52dc9b17-1182-44b3-bebf-ae2f508675d3",
   "metadata": {},
   "source": "# AgentCore Runtime での大容量マルチモーダルペイロードの処理\n\n## 概要\n\nこのチュートリアルでは、Amazon Bedrock AgentCore Runtime が Excel ファイルや画像などのマルチモーダルコンテンツを含む、最大 100MB の大容量ペイロードをどのように処理するかを実証します。AgentCore Runtime は、リッチメディアコンテンツと大きなデータセットをシームレスに処理するように設計されています。\n\n### チュートリアル詳細\n\n|項目| 詳細|\n|:--------------------|-|:---------------------------------------------------------------------------|\n| チュートリアル タイプ | 大容量ペイロードとマルチモーダル処理|\n| エージェント タイプ  | シングル         |\n| エージェントフレームワーク | Strands Agents |\n| LLM モデル          | Anthropic Claude Sonnet 3.7 |\n| チュートリアル コンポーネント | 大きなファイル処理、画像分析、Excel データ処理 |\n| チュートリアル領域   | データ分析とマルチモーダル AI                                               |\n| サンプルの複雑さ      | 中級                                                                     |\n| 使用 SDK            | Amazon BedrockAgentCore Python SDK|\n\n### 主な機能\n\n* **大容量ペイロードサポート**: 最大 100MB のサイズのファイルを処理\n* **マルチモーダル処理**: Excel ファイル、画像、テキストを同時に処理\n* **データ分析**: 構造化データと視覚コンテンツからインサイトを抽出\n* **Base64 エンコーディング**: JSON ペイロードを通じたバイナリデータの安全な送信"
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": "## 前提条件\n\n* Python 3.10+\n* 設定済みの AWS 認証情報\n* 実行中の Docker\n* テスト用のサンプル Excel ファイルと画像"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": "## サンプルデータファイルの作成\n\n大容量ペイロード処理を実証するために、サンプルの Excel と画像ファイルを作成しましょう："
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-sample-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# Create a large Excel file with sample sales data\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Date': pd.date_range('2023-01-01', periods=1000, freq='h'),\n",
    "    'Product': np.random.choice(['Widget A', 'Widget B', 'Widget C', 'Gadget X', 'Gadget Y'], 1000),\n",
    "    'Sales': np.random.randint(1, 1000, 1000),\n",
    "    'Revenue': np.random.uniform(10.0, 5000.0, 1000),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], 1000),\n",
    "    'Customer_ID': np.random.randint(1000, 9999, 1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel('large_sales_data.xlsx', index=False)\n",
    "\n",
    "# Create a sample chart image\n",
    "img = Image.new('RGB', (600, 500), color='white')\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Draw a simple bar chart\n",
    "products = ['Widget A', 'Widget B', 'Widget C', 'Gadget X', 'Gadget Y']\n",
    "values = [250, 180, 320, 150, 280]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "\n",
    "max_value = max(values)\n",
    "bar_width = 120\n",
    "start_x = 100\n",
    "\n",
    "for i, (product, value, color) in enumerate(zip(products, values, colors)):\n",
    "    x = start_x + i * (bar_width + 20)\n",
    "    height = int((value / max_value) * 400)\n",
    "    y = 500 - height\n",
    "    \n",
    "    # Draw bar\n",
    "    draw.rectangle([x, y, x + bar_width, 500], fill=color)\n",
    "    \n",
    "    # Add labels (simplified without font)\n",
    "    draw.text((x + 10, 510), product[:8], fill='black')\n",
    "    draw.text((x + 10, y - 20), str(value), fill='black')\n",
    "\n",
    "draw.text((300, 50), 'Sales Performance by Product', fill='black')\n",
    "img.save('sales_chart.png')\n",
    "\n",
    "# Check file sizes\n",
    "excel_size = os.path.getsize('large_sales_data.xlsx') / (1024 * 1024)  # MB\n",
    "image_size = os.path.getsize('sales_chart.png') / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"Excel file size: {excel_size:.2f} MB\")\n",
    "print(f\"Image file size: {image_size:.2f} MB\")\n",
    "print(f\"Total payload size: {excel_size + image_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-code",
   "metadata": {},
   "source": "## マルチモーダルエージェントの作成\n\n大容量ペイロードから Excel ファイルと画像の両方を処理できるエージェントを作成しましょう："
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b845b32-a03e-45c2-a2f0-2afba8069f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile multimodal_data_agent.py\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Initialize the model and agent\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    "    max_tokens=16000\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"\"\"\n",
    "    You are a data analysis assistant that can process large Excel files and images.\n",
    "    When given multi-modal data, analyze both the structured data and visual content,\n",
    "    then provide comprehensive insights combining both data sources.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def multimodal_data_processor(payload, context):\n",
    "    \"\"\"\n",
    "    Process large multi-modal payloads containing Excel data and images.\n",
    "    \n",
    "    Args:\n",
    "        payload: Contains prompt, excel_data (base64), image_data (base64)\n",
    "        context: Runtime context information\n",
    "    \n",
    "    Returns:\n",
    "        str: Analysis results from both data sources\n",
    "    \"\"\"\n",
    "    prompt = payload.get(\"prompt\", \"Analyze the provided data.\")\n",
    "    excel_data = payload.get(\"excel_data\", \"\")\n",
    "    image_data = payload.get(\"image_data\", \"\")\n",
    "    \n",
    "    print(f\"=== Large Payload Processing ===\")\n",
    "    print(f\"Session ID: {context.session_id}\")\n",
    "    \n",
    "    if excel_data:\n",
    "        print(f\"Excel data size: {len(excel_data) / 1024 / 1024:.2f} MB\")\n",
    "    if image_data:\n",
    "        print(f\"Image data size: {len(image_data) / 1024 / 1024:.2f} MB\")\n",
    "    print(f\"Excel data {excel_data}\")\n",
    "    print(f\"Image data {image_data}\")\n",
    "    print(f\"=== Processing Started ===\")\n",
    "    # Decode base64 to bytes\n",
    "    excel_bytes = base64.b64decode(excel_data)\n",
    "    # Decode base64 to bytes\n",
    "    image_bytes = base64.b64decode(image_data)\n",
    "    \n",
    "    # Enhanced prompt with data context\n",
    "    enhanced_prompt = f\"\"\"{prompt}\n",
    "    Please analyze both data sources and provide insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = agent(\n",
    "        [{\n",
    "            \"document\": {\n",
    "                \"format\": \"xlsx\",\n",
    "                \"name\": \"excel_data\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": excel_bytes\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": image_bytes\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"text\": enhanced_prompt\n",
    "        }]\n",
    "    )\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-infrastructure",
   "metadata": {},
   "source": "## インフラストラクチャのセットアップとエージェントのデプロイ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"multimodal_data_agent.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=\"multimodal_data_agent\"\n",
    ")\n",
    "\n",
    "launch_result = agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-for-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(f\"Deployment status: {status}\")\n",
    "\n",
    "print(f\"Final status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-large-payloads",
   "metadata": {},
   "source": "## 大容量マルチモーダルペイロードのテスト\n\n次に、Excel データと画像の両方を含む大容量ペイロードでエージェントをテストしましょう："
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import uuid\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Encode files to base64\n",
    "with open('large_sales_data.xlsx', 'rb') as f:\n",
    "    excel_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "with open('sales_chart.png', 'rb') as f:\n",
    "    image_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "# Create large payload\n",
    "large_payload = {\n",
    "    \"prompt\": \"Analyze the sales data from the Excel file and correlate it with the chart image. Provide insights on sales performance and trends.\",\n",
    "    \"excel_data\": excel_base64,\n",
    "    \"image_data\": image_base64\n",
    "}\n",
    "\n",
    "session_id = str(uuid.uuid4())\n",
    "print(f\"📊 Processing large multi-modal payload...\")\n",
    "print(f\"📋 Session ID: {session_id}\")\n",
    "print(f\"📄 Excel size: {len(excel_base64) / 1024 / 1024:.2f} MB\")\n",
    "print(f\"🖼️ Image size: {len(image_base64) / 1024 / 1024:.2f} MB\")\n",
    "print(f\"📦 Total payload: {len(json.dumps(large_payload)) / 1024 / 1024:.2f} MB\\n\")\n",
    "\n",
    "# Invoke agent with large payload\n",
    "invoke_response = agentcore_runtime.invoke(\n",
    "    large_payload,\n",
    "    session_id=session_id\n",
    ")\n",
    "final_response = \"\"\n",
    "for r in invoke_response['response']:\n",
    "    final_response += r.decode(\"utf-8\")\n",
    "response_data = json.loads(final_response)\n",
    "display(Markdown(response_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": "## リソースのクリーンアップ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-resources",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Clean up AWS resources\n",
    "agentcore_control_client = boto3.client('bedrock-agentcore-control', region_name=region)\n",
    "ecr_client = boto3.client('ecr', region_name=region)\n",
    "\n",
    "# Delete AgentCore Runtime\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "# Delete ECR repository\n",
    "ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "# Clean up local files\n",
    "os.remove('large_sales_data.xlsx')\n",
    "os.remove('sales_chart.png')\n",
    "\n",
    "print(\"✅ Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": "# おめでとうございます！\n\nAmazon Bedrock AgentCore Runtime を使用した大容量マルチモーダルペイロードの処理に成功しました！\n\n## 学んだこと：\n\n### 大容量ペイロード処理\n* **100MB サポート**: AgentCore Runtime は最大 100MB のペイロードを処理可能\n* **Base64 エンコーディング**: JSON ペイロードを通じたバイナリデータの安全な送信\n* **効率的な処理**: 大きなデータ処理に最適化されたランタイム\n\n### マルチモーダル機能\n* **Excel 分析**: スプレッドシートからの構造化データの処理\n* **画像処理**: 視覚的コンテンツとチャートの分析\n* **統合分析**: 複数のデータタイプからのインサイトの相関\n\n### 主な利点\n* **豊富なデータ処理**: 複雑で複数形式のデータセットを処理\n* **スケーラブルなアーキテクチャ**: 大きなワークロードに対応したランタイム設計\n* **ツール統合**: 特化したデータ処理用のカスタムツール\n* **エンタープライズ対応**: 機密ビジネスデータの安全な処理\n\nこれは、複雑なビジネスインテリジェンスとデータ分析アプリケーションに理想的な、複数のデータモダリティを持つエンタープライズスケールのデータ処理タスクを処理する AgentCore Runtime の機能を実証しています。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}